{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trademark Case Files Dataset\n",
    "\n",
    "This dataset is found at https://www.uspto.gov/learning-and-resources/electronic-data-products/trademark-case-files-dataset-0.\n",
    "\n",
    "The Trademark Case Files Dataset contains detailed information on 8.6 million trademark applications filed with or registrations issued by the USPTO between January 1870 and January 2017. It is derived from the USPTO main database for administering trademarks and includes data on mark characteristics, prosecution events, ownership, classification, third-party oppositions, and renewal history.\n",
    "\n",
    "Full schema can be found at: https://www.uspto.gov/sites/default/files/documents/casefiles_schema_high_level_2016update.pdf\n",
    "\n",
    "Data dictionary found at: https://www.uspto.gov/sites/default/files/documents/vartable_2016.pdf\n",
    "\n",
    "For this analysis we'll only use the Case files, owners (and related owner change table), and events table for exploring some details on existing and past trademark applications and registrations, the parties which own them, and their history of administrative actions taken from beginning to end.\n",
    "\n",
    "More details on the full dataset can be found in this publication from the US Patent and Trademark office: http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2188621"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load our packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlContext.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load our data\n",
    "#### Case files data: \n",
    "Table which describe the current status of all trademark applications from 1870 - 2017 as of the time of the last data update (January 2017). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val case_files_data = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option(\"mode\", \"DROPMALFORMED\").option(\"inferSchema\", \"true\").load(\"hdfs://sandbox.hortonworks.com:8020/tmp/case_file.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case files data is quite large (over 8,000,000 records) and wide (79) variables. Let's just grab the columns we're interested in after reviewing the data schema here (https://www.uspto.gov/sites/default/files/documents/vartable_2016.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val case_files_cols = Seq(\"serial_no\",\n",
    "\"abandon_dt\",\n",
    "\"amend_reg_dt\",\n",
    "\"reg_cancel_cd\",\n",
    "\"reg_cancel_dt\",\n",
    "\"cancel_pend_in\",\n",
    "\"cert_mark_in\",\n",
    "\"chg_reg_in\",\n",
    "\"coll_memb_mark_in\",\n",
    "\"coll_serv_mark_in\",\n",
    "\"coll_trade_mark_in\",\n",
    "\"serv_mark_in\",\n",
    "\"draw_color_cur_in\",\n",
    "\"draw_color_file_in\",\n",
    "\"concur_use_in\",\n",
    "\"concur_use_pend_in\",\n",
    "\"filing_dt\",\n",
    "\"for_priority_in\",\n",
    "\"lb_itu_cur_in\",\n",
    "\"lb_itu_file_in\",\n",
    "\"interfer_pend_in\",\n",
    "\"exm_office_cd\",\n",
    "\"file_location_dt\",\n",
    "\"mark_draw_cd\",\n",
    "\"mark_id_char\",\n",
    "\"opposit_pend_in\",\n",
    "\"amend_principal_in\",\n",
    "\"concur_use_pub_in\",\n",
    "\"publication_dt\",\n",
    "\"registration_dt\",\n",
    "\"renewal_dt\",\n",
    "\"renewal_file_in\",\n",
    "\"cfh_status_cd\",\n",
    "\"cfh_status_dt\",\n",
    "\"trade_mark_in\",\n",
    "\"registration_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val case_files_lite = case_files_data.select(case_files_cols.head, case_files_cols.tail: _*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, since this covers such wide range of time (almost 150 years of trademark registrations!), we want to look at trends over the years. We'll create year columns for all of the date columns since we'll access them a lot and don't want to regularly have to compute on the fly from the date columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val case_files_lite_years = case_files_lite.\n",
    "                            withColumn(\"filing_yr\",year(case_files_lite(\"filing_dt\"))).\n",
    "                            withColumn(\"abandon_yr\",year(case_files_lite(\"abandon_dt\"))).\n",
    "                            withColumn(\"publication_yr\",year(case_files_lite(\"publication_dt\"))).\n",
    "                            withColumn(\"registration_yr\",year(case_files_lite(\"registration_dt\"))).\n",
    "                            withColumn(\"cfh_status_yr\",year(case_files_lite(\"cfh_status_dt\"))).\n",
    "                            withColumn(\"renewal_yr\",year(case_files_lite(\"renewal_dt\"))).\n",
    "                            withColumn(\"reg_cancel_yr\",year(case_files_lite(\"reg_cancel_dt\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's then write out the derivative to a parquet file so we don't need to do this everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.sql.AnalysisException\n",
       "Message: path hdfs://sandbox.hortonworks.com:8020/tmp/case_files_processed.parquet already exists.;\n",
       "StackTrace:   at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:80)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource.writeInFileFormat(DataSource.scala:484)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource.write(DataSource.scala:520)\n",
       "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:215)\n",
       "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:198)\n",
       "  at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:494)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_files_lite_years.write.parquet(\"hdfs://sandbox.hortonworks.com:8020/tmp/case_files_processed.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's load it back in for faster traversal of the case files data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val case_files = sqlContext.read.parquet(\"hdfs://sandbox.hortonworks.com:8020/tmp/case_files_processed.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Events data:\n",
    "Table which describes the event history of each trademark application from initiation through registration (or denial) and includes renewals, abandonments, and expiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val events_raw = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option(\"mode\", \"DROPMALFORMED\").option(\"inferSchema\", \"true\").load(\"hdfs://sandbox.hortonworks.com:8020/tmp/event.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Owners and owner change data:\n",
    "Two tables that track the owning parties and history of changes of ownership of trademarks in the Case files table. Owners related to case files table through serial number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val owners_raw = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option(\"mode\", \"DROPMALFORMED\").option(\"inferSchema\", \"true\").load(\"hdfs://sandbox.hortonworks.com:8020/tmp/owner.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Trends in types of  trademarks (service mark, trademark, certification mark, or collective mark)\n",
    "- Ref: https://www.bitlaw.com/source/tmep/1306_01.html\n",
    "- Check mark type for trends in service mark registrations like the dotcom boom\n",
    "- Can we see an increase in trademark applications in general like the 1990s dotcom boom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val service_marks = case_files.filter($\"serv_mark_in\" === 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2892932"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_marks.count() //this is about a third of the total observations, as mentioned in the publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val service_counts = service_apps.filter($\"filing_yr\".isNotNull).groupBy(\"filing_yr\").agg(count(\"*\") as \"year_count\").orderBy($\"filing_yr\" asc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|filing_yr|year_count|\n",
      "+---------+----------+\n",
      "|     1899|         1|\n",
      "|     1911|         1|\n",
      "|     1915|         1|\n",
      "|     1931|         3|\n",
      "|     1932|         3|\n",
      "|     1933|         1|\n",
      "|     1934|         1|\n",
      "|     1935|         1|\n",
      "|     1937|         1|\n",
      "|     1938|         2|\n",
      "|     1939|         3|\n",
      "|     1944|         1|\n",
      "|     1946|         4|\n",
      "|     1947|       170|\n",
      "|     1948|       142|\n",
      "|     1949|        87|\n",
      "|     1950|        86|\n",
      "|     1951|        82|\n",
      "|     1952|       115|\n",
      "|     1953|       140|\n",
      "|     1954|       136|\n",
      "|     1955|       145|\n",
      "|     1956|       142|\n",
      "|     1957|       143|\n",
      "|     1958|       160|\n",
      "|     1959|       221|\n",
      "|     1960|       311|\n",
      "|     1961|       582|\n",
      "|     1962|       639|\n",
      "|     1963|       550|\n",
      "|     1964|       719|\n",
      "|     1965|       864|\n",
      "|     1966|      1025|\n",
      "|     1967|      1146|\n",
      "|     1968|      1444|\n",
      "|     1969|      1916|\n",
      "|     1970|      1875|\n",
      "|     1971|      1754|\n",
      "|     1972|      2048|\n",
      "|     1973|      2131|\n",
      "|     1974|      2278|\n",
      "|     1975|      3329|\n",
      "|     1976|      4970|\n",
      "|     1977|      5882|\n",
      "|     1978|      6575|\n",
      "|     1979|      6965|\n",
      "|     1980|      8125|\n",
      "|     1981|     11402|\n",
      "|     1982|     15122|\n",
      "|     1983|     12519|\n",
      "|     1984|     14012|\n",
      "|     1985|     15439|\n",
      "|     1986|     15793|\n",
      "|     1987|     17460|\n",
      "|     1988|     18293|\n",
      "|     1989|     22557|\n",
      "|     1990|     28798|\n",
      "|     1991|     28360|\n",
      "|     1992|     29175|\n",
      "|     1993|     35953|\n",
      "|     1994|     40625|\n",
      "|     1995|     49132|\n",
      "|     1996|     62051|\n",
      "|     1997|     67096|\n",
      "|     1998|     73525|\n",
      "|     1999|    119649|\n",
      "|     2000|    143179|\n",
      "|     2001|     88601|\n",
      "|     2002|     81917|\n",
      "|     2003|     84362|\n",
      "|     2004|     96163|\n",
      "|     2005|    106970|\n",
      "|     2006|    119890|\n",
      "|     2007|    135395|\n",
      "|     2008|    129693|\n",
      "|     2009|    116888|\n",
      "|     2010|    123036|\n",
      "|     2011|    137637|\n",
      "|     2012|    141078|\n",
      "|     2013|    143874|\n",
      "|     2014|    153292|\n",
      "|     2015|    167068|\n",
      "|     2016|    165878|\n",
      "|     2017|     17895|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_counts.show(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty interesting. The original authors noticed a spike in service trademarks leading up to the dotcom boom with a noticeable drop off in 2001 thorugh 2004. Since 2005, we're seeing service trademarks steadily rise again, only dipping perhaps trivially after the economic crash of Oct 2008, only to steadily rise to historic highs in 2015 and 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//lets save that table out to csv so we can visualize later\n",
    "service_counts.write.csv(\"hdfs://sandbox.hortonworks.com:8020/tmp/output/service_counts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Getting a little more complicated and looking at the bigger picture of which trademarks are opposed vs. those that are published.\n",
    "- Do oppositions increase over time as more and more trademarks are registered, or do the stay pretty stable?\n",
    "    - Service mark, trademark, certification mark (?) - only reason to join to case_file table\n",
    "    - Bucket and aggregate by year\n",
    "    - When were oppositions generated?\n",
    "    - When were most oppositions sustained?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Events are logged in the event table and of the 799 different event statuses (see https://eipweb.uspto.gov/TrademarkCaseFileEconomics/2011/event_description.csv.zip), we want to examine those involving oppositions, or rather, the action, after a trademark is accepted by the examiners, it is \"Published for opposition\" for third parties to make a claim that challenges a trademark currently in process of being registered. There are 5 statuses we'll look at from the event_description file:\n",
    "\n",
    "\n",
    "| event_code | event_type | event_desc                                     | event_count |\n",
    "|------------|------------|------------------------------------------------|-------------|\n",
    "| PUBO       | A          | PUBLISHED FOR OPPOSITION                       | 5399155     |\n",
    "| R.PR       | A          | REGISTERED-PRINCIPAL REGISTER                  | 3852684     |\n",
    "| OP.I       | T          | OPPOSITION INSTITUTED NO. 999999               | 147676      |\n",
    "| OP.T\t     | T \t      | OPPOSITION TERMINATED NO. 999999\t           | 144702      |\n",
    "| OP.D       | T          | OPPOSITION DISMISSED NO. 999999                | 78278       |\n",
    "| OP.S       | T          | OPPOSITION SUSTAINED NO. 999999                | 61363       |\n",
    "\n",
    "After **PUBLISHED FOR OPPOSITION** the next major event to indicate that an opposition has actually been made is **OPPOSITION INSTITUTED**. Of that subset, the two major are outcomes are either **OPPOSITION DISMISSED** (and it can go on to be registered) or **OPPOSITION SUSTAINED** (and it will go on to be abandoned).\n",
    "\n",
    "*Note*: As there are so many different event codes and vmany different ways for an application to move through the trademark application process, there are events we are not accounting for in this analysis. With more time and understanding of the trademark process we'd be able to address those additional factors. But for this analysis, that we are focusing on the majority of outcomes related to opposing a trademark registration, this is at least somewhat informative.\n",
    "\n",
    "**And so we ask**: Over time, when were opposition instituted most prevelant, and when were there more or less oppositions sustained (as related to the number of applications published for opposition and registered principal register by year)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a little more complicated in that it involves some table joining and more computation, how do we want to do this w/o making out infrastructure suffer?\n",
    "\n",
    "- **Hive** (No. Just use parquet since this is a one time analysis and we just want to pinpoint specific columns to work with to answer a few simple questions. If we intended to do longitudinal, regularly updated analyses which depending on reliable ACID transactions we might create a pipeline into Hive for persistence. For now parquet should suffice for improviing query performance on a quasi-static dataset)\n",
    "- **Broadcast variables?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 Owners:\n",
    "- Who has the most trademarks?\n",
    "- What are some trends in ownership over time?\n",
    "    - see owner table and join with case_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:17: error: not found: value owners_raw\n",
       "       val uown = owners_raw.groupBy(\"own_type_cd\").agg(count(\"*\") as \"own_count\").orderBy($\"own_count\" desc)\n",
       "                  ^\n",
       "<console>:17: error: not found: value count\n",
       "       val uown = owners_raw.groupBy(\"own_type_cd\").agg(count(\"*\") as \"own_count\").orderBy($\"own_count\" desc)\n",
       "                                                        ^\n",
       "<console>:17: error: value $ is not a member of StringContext\n",
       "       val uown = owners_raw.groupBy(\"own_type_cd\").agg(count(\"*\") as \"own_count\").orderBy($\"own_count\" desc)\n",
       "                                                                                           ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val uown = owners_raw.groupBy(\"own_type_cd\").agg(count(\"*\") as \"own_count\").orderBy($\"own_count\" desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: length of marks over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val case_mark_lengths = case_files.filter($\"filing_yr\".isNotNull && $\"mark_id_char\".isNotNull).select(\"mark_id_char\", \"filing_yr\").withColumn(\"count\", size(split($\"mark_id_char\", \" \"))).orderBy($\"filing_yr\" asc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val avg_mark_counts = case_mark_lengths.groupBy(\"filing_yr\").agg(mean(\"count\")).orderBy($\"filing_yr\" asc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.sql.AnalysisException\n",
       "Message: path hdfs://sandbox.hortonworks.com:8020/tmp/output/avg_mark_counts.csv already exists.;\n",
       "StackTrace:   at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:80)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource.writeInFileFormat(DataSource.scala:484)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource.write(DataSource.scala:520)\n",
       "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:215)\n",
       "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:198)\n",
       "  at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:579)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_mark_counts.write.csv(\"hdfs://sandbox.hortonworks.com:8020/tmp/output/avg_mark_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
