{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlContext.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create \"histogram\" of counts by home_ownership type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").load(\"hdfs://sandbox.hortonworks.com:8020/tmp/loan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val home_own = df.groupBy(\"home_ownership\").count().orderBy($\"count\".desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+--------------+------+\n",
      "|home_ownership| count|\n",
      "+--------------+------+\n",
      "|      MORTGAGE|443455|\n",
      "|          RENT|355986|\n",
      "|           OWN| 87449|\n",
      "|         OTHER|   181|\n",
      "|          NONE|    50|\n",
      "|           ANY|     3|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "home_own.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. a) Since we have a lot of columns, and it can be expensive to walk every column of a row in a query, we might try a columnar data format like parquet. With our data in columnar format, we only look through the columns we are interested in a given query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. b) Convert to parquet and run a couple queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.sql.AnalysisException\n",
       "Message: path hdfs://sandbox.hortonworks.com:8020/tmp/loan_columnar.csv already exists.;\n",
       "StackTrace:   at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:80)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource.writeInFileFormat(DataSource.scala:484)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource.write(DataSource.scala:520)\n",
       "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:215)\n",
       "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:198)\n",
       "  at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:494)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.write.parquet(\"hdfs://sandbox.hortonworks.com:8020/tmp/loan_columnar.csv\") //only need to run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val pq_df = sqlContext.read.parquet(\"hdfs://sandbox.hortonworks.com:8020/tmp/loan_columnar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "val home_own_pq = pq_df.groupBy(\"home_ownership\").count().orderBy($\"count\".desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|home_ownership| count|\n",
      "+--------------+------+\n",
      "|      MORTGAGE|443455|\n",
      "|          RENT|355986|\n",
      "|           OWN| 87449|\n",
      "|         OTHER|   181|\n",
      "|          NONE|    50|\n",
      "|           ANY|     3|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "home_own_pq.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That ran quite a bit faster than the groupBy count with the csv file.\n",
    "\n",
    "Let's try some other operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+-----------+------------------+-----------+----------------+-----+--------------+-------+------+-----+----------------+--------------+--------+-------+\n",
      "|application_type| car|credit_card|debt_consolidation|educational|home_improvement|house|major_purchase|medical|moving|other|renewable_energy|small_business|vacation|wedding|\n",
      "+----------------+----+-----------+------------------+-----------+----------------+-----+--------------+-------+------+-----+----------------+--------------+--------+-------+\n",
      "|           JOINT|   1|        115|               334|       null|              26| null|             2|      2|     1|   27|            null|             2|       1|   null|\n",
      "|      INDIVIDUAL|8858|     206022|            523794|        411|           51786| 3702|         17259|   8531|  5412|42840|             575|         10345|    4735|   2343|\n",
      "+----------------+----+-----------+------------------+-----------+----------------+-----+--------------+-------+------+-----+----------------+--------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pq_df.groupBy(\"application_type\").pivot(\"purpose\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+-----------+------------------+-----------+----------------+-----+--------------+-------+------+-----+----------------+--------------+--------+-------+\n",
      "|application_type| car|credit_card|debt_consolidation|educational|home_improvement|house|major_purchase|medical|moving|other|renewable_energy|small_business|vacation|wedding|\n",
      "+----------------+----+-----------+------------------+-----------+----------------+-----+--------------+-------+------+-----+----------------+--------------+--------+-------+\n",
      "|           JOINT|   1|        115|               334|       null|              26| null|             2|      2|     1|   27|            null|             2|       1|   null|\n",
      "|      INDIVIDUAL|8858|     206022|            523794|        411|           51786| 3702|         17259|   8531|  5412|42840|             575|         10345|    4735|   2343|\n",
      "+----------------+----+-----------+------------------+-----------+----------------+-----+--------------+-------+------+-----+----------------+--------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"application_type\").pivot(\"purpose\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+------------------+\n",
      "|       loan_status|zip_code|avg(loan_amnt_int)|\n",
      "+------------------+--------+------------------+\n",
      "|Late (31-120 days)|   010xx|           14355.0|\n",
      "|Late (31-120 days)|   011xx| 15930.76923076923|\n",
      "|Late (31-120 days)|   012xx|16416.666666666668|\n",
      "|Late (31-120 days)|   013xx|           10500.0|\n",
      "|Late (31-120 days)|   014xx| 18867.30769230769|\n",
      "|Late (31-120 days)|   015xx| 19110.29411764706|\n",
      "|Late (31-120 days)|   016xx|12338.888888888889|\n",
      "|Late (31-120 days)|   017xx| 15294.23076923077|\n",
      "|Late (31-120 days)|   018xx|14456.060606060606|\n",
      "|Late (31-120 days)|   019xx| 17669.31818181818|\n",
      "|Late (31-120 days)|   020xx| 22032.14285714286|\n",
      "|Late (31-120 days)|   021xx|           15600.0|\n",
      "|Late (31-120 days)|   023xx|        15057.8125|\n",
      "|Late (31-120 days)|   024xx|          20743.75|\n",
      "|Late (31-120 days)|   025xx|           14900.0|\n",
      "|Late (31-120 days)|   026xx|           17540.0|\n",
      "|Late (31-120 days)|   027xx| 19380.68181818182|\n",
      "|Late (31-120 days)|   028xx|14896.794871794871|\n",
      "|Late (31-120 days)|   029xx|           15497.5|\n",
      "|Late (31-120 days)|   030xx|15406.666666666666|\n",
      "+------------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pq_df.withColumn(\"loan_amnt_int\", pq_df(\"loan_amnt\").cast(IntegerType)).groupBy(\"loan_status\", \"zip_code\").avg(\"loan_amnt_int\").orderBy($\"loan_status\".desc, $\"zip_code\".asc).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+------------------+--------+------------------+\n",
      "|       loan_status|zip_code|avg(loan_amnt_int)|\n",
      "+------------------+--------+------------------+\n",
      "|Late (31-120 days)|   010xx|           14355.0|\n",
      "|Late (31-120 days)|   011xx| 15930.76923076923|\n",
      "|Late (31-120 days)|   012xx|16416.666666666668|\n",
      "|Late (31-120 days)|   013xx|           10500.0|\n",
      "|Late (31-120 days)|   014xx| 18867.30769230769|\n",
      "|Late (31-120 days)|   015xx| 19110.29411764706|\n",
      "|Late (31-120 days)|   016xx|12338.888888888889|\n",
      "|Late (31-120 days)|   017xx| 15294.23076923077|\n",
      "|Late (31-120 days)|   018xx|14456.060606060606|\n",
      "|Late (31-120 days)|   019xx| 17669.31818181818|\n",
      "|Late (31-120 days)|   020xx| 22032.14285714286|\n",
      "|Late (31-120 days)|   021xx|           15600.0|\n",
      "|Late (31-120 days)|   023xx|        15057.8125|\n",
      "|Late (31-120 days)|   024xx|          20743.75|\n",
      "|Late (31-120 days)|   025xx|           14900.0|\n",
      "|Late (31-120 days)|   026xx|           17540.0|\n",
      "|Late (31-120 days)|   027xx| 19380.68181818182|\n",
      "|Late (31-120 days)|   028xx|14896.794871794871|\n",
      "|Late (31-120 days)|   029xx|           15497.5|\n",
      "|Late (31-120 days)|   030xx|15406.666666666666|\n",
      "+------------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"loan_amnt_int\", df(\"loan_amnt\").cast(IntegerType)).groupBy(\"loan_status\", \"zip_code\").avg(\"loan_amnt_int\").orderBy($\"loan_status\".desc, $\"zip_code\".asc).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parquet seems to be a bit faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Counts by loan_status by home_ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val loan_stat_pq = pq_df.groupBy(\"home_ownership\", \"loan_status\").count().orderBy($\"home_ownership\".desc, $\"count\".desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+------+\n",
      "|home_ownership|         loan_status| count|\n",
      "+--------------+--------------------+------+\n",
      "|          RENT|             Current|235966|\n",
      "|          RENT|          Fully Paid| 84547|\n",
      "|          RENT|         Charged Off| 21293|\n",
      "|          RENT|  Late (31-120 days)|  5360|\n",
      "|          RENT|              Issued|  3202|\n",
      "|          RENT|     In Grace Period|  2761|\n",
      "|          RENT|   Late (16-30 days)|   996|\n",
      "|          RENT|Does not meet the...|   903|\n",
      "|          RENT|             Default|   611|\n",
      "|          RENT|Does not meet the...|   347|\n",
      "|           OWN|             Current| 62041|\n",
      "|           OWN|          Fully Paid| 17945|\n",
      "|           OWN|         Charged Off|  4021|\n",
      "|           OWN|  Late (31-120 days)|  1212|\n",
      "|           OWN|              Issued|  1038|\n",
      "|           OWN|     In Grace Period|   637|\n",
      "|           OWN|   Late (16-30 days)|   260|\n",
      "|           OWN|Does not meet the...|   137|\n",
      "|           OWN|             Default|   110|\n",
      "|           OWN|Does not meet the...|    48|\n",
      "+--------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_stat_pq.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 4. Any loans originate in King County based on wa_zipcodes.csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val wa_zip_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").load(\"hdfs://sandbox.hortonworks.com:8020/tmp/wa_zipcodes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get all zipcodes to an array for checking, since we're only interested in the first three digits, we'll drop the rest of the zipcode and make a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "val wa_zips = wa_zip_df.select(\"Zipcode\").rdd.map(r => r(0).toString.dropRight(2).concat(\"xx\")).collect().distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(980xx, 981xx, 982xx)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa_zips.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "val res = pq_df.filter($\"zip_code\".isin(wa_zips:_*))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9576"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, there are evidently 9576 loans originating in King County"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
